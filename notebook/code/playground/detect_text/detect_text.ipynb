{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import typing as t\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working folders and load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_p = \"./evaluation/\"\n",
    "in_p = working_p\n",
    "out_p = working_p\n",
    "\n",
    "# order number used for giving name to output images\n",
    "ordn = 0\n",
    "\n",
    "# get only folders in in_p\n",
    "folders = [f for f in os.listdir(in_p) if os.path.isdir(os.path.join(in_p, f))]\n",
    "\n",
    "imgs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img(img, file: str, s) -> str:\n",
    "    \"\"\"\n",
    "    Saves the image with the formated name: <out_path>/<file_name>[-<s>].<file_ext>\n",
    "    Note: <out_path> is a global variable '/' terminated\n",
    "    Note: By default extension is \".png\"\n",
    "    \n",
    "    @param img: the image to save\n",
    "    @param file: the name of the file to save\n",
    "\n",
    "    @return: the path and name of the file saved\n",
    "    \"\"\"\n",
    "\n",
    "    file_name = file\n",
    "    file_ext = \"png\"\n",
    "    if file.count(\".\") > 0:\n",
    "        file_name = \".\".join([x for x in file.split(\".\")[:-1]])\n",
    "        file_ext = file.split(\".\")[-1]\n",
    "\n",
    "    # if type of s is string, then it is the suffix\n",
    "    # else if type of s is list, then add multiple suffizes\n",
    "    # else add s as it is\n",
    "    suffix = \"\"\n",
    "    if type(s) is str:\n",
    "        suffix = [s]\n",
    "    elif  type(s) is list:\n",
    "        suffix = s\n",
    "    else:\n",
    "        suffix = [str(s)]\n",
    "\n",
    "    global ordn\n",
    "    file_out = out_p + file_name + \"-\" + str(ordn) + \"-\"  + \"-\".join(suffix) + \".\" + file_ext\n",
    "    ordn += 1\n",
    "\n",
    "    cv2.imwrite(file_out, img)\n",
    "\n",
    "    return file_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for bitmap detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_fft(img):\n",
    "    \"\"\"\n",
    "    It takes in a square gray image and processes it to get the frequency domain image.\n",
    "\n",
    "    @param img: a square gray image\n",
    "\n",
    "    @return: a tuple of the frequency domain image and the magnitude spectrum\n",
    "    \"\"\"\n",
    "    f = np.fft.fft2(img)\n",
    "    fshift = np.fft.fftshift(f)\n",
    "    magnitude_spectrum = 20*np.log(np.abs(fshift))\n",
    "\n",
    "    # f = cv2.dft(np.float32(img), flags=cv2.DFT_COMPLEX_OUTPUT)\n",
    "    # fshift = np.fft.fftshift(f)\n",
    "    # magnitude_spectrum = 20*np.log(cv2.magnitude(fshift[:,:,0],fshift[:,:,1]))\n",
    "    \n",
    "    return (fshift, magnitude_spectrum)\n",
    "\n",
    "def do_ifft(fshift):\n",
    "    f_ishift = np.fft.ifftshift(fshift)\n",
    "    \n",
    "    img_back = np.fft.ifft2(f_ishift)\n",
    "    img_back = np.abs(img_back)\n",
    "\n",
    "    # img_back = cv2.idft(f_ishift)\n",
    "    # img_back = cv2.magnitude(img_back[:,:,0],img_back[:,:,1])\n",
    "\n",
    "    return img_back\n",
    "\n",
    "def do_keep_disk(fshift, sr, br):\n",
    "    \"\"\"\n",
    "    Keeps only the disk from fshift (frequency domain image). The disk is in the center of the image.\n",
    "\n",
    "    @param fshift: the frequency domain image (of square shape)\n",
    "    @param sr: the small radius of the disk to keep (in procents, maximum is 50% of the image size)\n",
    "    @param br: the big radius of the disk to keep (in procents, maximum is 50% of the image size)\n",
    "    \n",
    "    @return: the frequency domain image with only the disk part kept\n",
    "    \"\"\"\n",
    "\n",
    "    rows = fshift.shape[0]\n",
    "    cols = fshift.shape[1]\n",
    "    crow,ccol = int(rows/2) , int(cols/2)\n",
    "    \n",
    "    big_r = int(rows * br / 100)\n",
    "    small_r = int(rows * sr / 100)\n",
    "    med_r = abs(int(big_r - (big_r - small_r) / 2))\n",
    "\n",
    "    empty_img = np.zeros((rows, cols), np.uint8)\n",
    "    cv2.circle(empty_img, (ccol, crow), med_r, color=1, thickness=abs(big_r - small_r))\n",
    "\n",
    "    if len(fshift.shape) == 3 and fshift.shape[2] == 2:\n",
    "        empty_img = empty_img.reshape((rows, cols, 1))\n",
    "    \n",
    "    fshift = fshift * empty_img\n",
    "\n",
    "    return fshift\n",
    "\n",
    "def get_bitmap_of_possible_text(img, sr: int, br: int, scale: int, file = \"file.png\", DEBUG: bool = False):\n",
    "    \"\"\"\n",
    "    It thakes in a square gray image and processes it to hopefully remain with a bitmap of where text if present.\n",
    "    The processing steps are:\n",
    "\n",
    "    @param img: a square gray image\n",
    "    @param sr: the small radius of the disk to keep (in procents, maximum is 50% of the image size)\n",
    "    @param br: the big radius of the disk to keep (in procents, maximum is 50% of the image size)\n",
    "    @param scale: how much to scale the remained frequencies after the disk is kept\n",
    "\n",
    "    @return: a bitmap of where text is present\n",
    "    \"\"\"\n",
    "\n",
    "    (fshift, magnitude_spectrum_original) = do_fft(img)\n",
    "\n",
    "    # keep only disk from fshift\n",
    "    fshift = do_keep_disk(fshift, sr, br)\n",
    "\n",
    "    # increase the frequencies\n",
    "    fshift *= scale\n",
    "\n",
    "    # do inverse fft with the filtered frequencies\n",
    "    img_filtered = do_ifft(fshift)\n",
    "    img_filtered = cv2.convertScaleAbs(img_filtered)\n",
    "\n",
    "    # use blackhat\n",
    "    img_filtered = cv2.morphologyEx(img_filtered, cv2.MORPH_BLACKHAT, np.ones((3,3), np.uint8))\n",
    "\n",
    "    # use OTSU global thresholding\n",
    "    thresh, img_otsu = cv2.threshold(img_filtered, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "    if DEBUG:\n",
    "        # print(\"fshift -> \" + file)\n",
    "        # print(fshift)\n",
    "        # print(fshift.shape)\n",
    "        save_img(magnitude_spectrum_original, file, \"magnitude_spectrum-original\")\n",
    "        save_img(20*np.log(np.abs(fshift)), file, \"magnitude_spectrum-modified\")\n",
    "        # save_img(20*np.log(cv2.magnitude(fshift[:,:,0],fshift[:,:,1])), file, \"magnitude_spectrum-modified\")\n",
    "        save_img(img_filtered, file, \"img_filtered\")\n",
    "        print(file + \" OTSU T: \" + str(thresh))\n",
    "        save_img(img_otsu, file, \"img_otsu\")\n",
    "\n",
    "    return img_otsu\n",
    "\n",
    "def _is_noise(h, w, shape) -> bool:\n",
    "    bh, bw = shape\n",
    "    \n",
    "    if (h < 10 or w < 10):\n",
    "        return True\n",
    "    elif h / w > 1.5:\n",
    "        return True\n",
    "    elif h / w < 0.33:\n",
    "        return True\n",
    "    elif  (h > bh * 0.33) and (w > bw * 0.66):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def _is_not_text(h, w, shape) -> bool:\n",
    "    bh, bw = shape\n",
    "\n",
    "    if h < 26 or w < 10:\n",
    "        return True\n",
    "    elif h / w > 1.5:\n",
    "        return True\n",
    "    elif h / w < 0.33:\n",
    "        return True\n",
    "    elif  (h > bh * 0.33) and (w > bw * 0.66):\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def filter_for_text(bitmap, file = \"file.png\", DEBUG: bool = False):\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    result = bitmap\n",
    "\n",
    "    # dilate\n",
    "    result = cv2.dilate(result, kernel, iterations=1)\n",
    "\n",
    "    cnts = cv2.findContours(result.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    ci_first_boxes = cv2.cvtColor(result, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    for c in cnts:\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        # draw bounding rectangle\n",
    "        cv2.rectangle(ci_first_boxes, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "\n",
    "        if _is_noise(h, w, bitmap.shape):\n",
    "            result[y:y+h, x:x+w] = 0\n",
    "\n",
    "    # dilate once more\n",
    "    result = cv2.dilate(result, kernel, iterations=4)\n",
    "\n",
    "    ci_second_boxes = cv2.cvtColor(result, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    cnts = cv2.findContours(result.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    for c in cnts:\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        # draw bounding rectangle\n",
    "        cv2.rectangle(ci_second_boxes, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "        \n",
    "        # remove big boxes that have a lot of black pixels\n",
    "        white_percentage = np.sum(result[y:y+h, x:x+w] == 255) / (h * w)\n",
    "        if (white_percentage < 0.40):\n",
    "            result[y:y+h, x:x+w] = 0\n",
    "        elif _is_not_text(h, w, bitmap.shape):\n",
    "            result[y:y+h, x:x+w] = 0\n",
    "        elif (h > bitmap.shape[0] * 0.4) and (h / w < 1.0):\n",
    "            result[y:y+h, x:x+w] = 0\n",
    "        elif (h > bitmap.shape[0] * 0.7):\n",
    "            result[y:y+h, x:x+w] = 0\n",
    "\n",
    "    # put colorful bounding boxex on the image\n",
    "    cnts = cv2.findContours(result.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    after_filter = cv2.cvtColor(result, cv2.COLOR_GRAY2BGR)\n",
    "    for c in cnts:\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        # draw bounding rectangle\n",
    "        cv2.rectangle(after_filter, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    if DEBUG:\n",
    "        save_img(ci_first_boxes, file, \"first_boxes\")\n",
    "        save_img(ci_second_boxes, file, \"second_boxes\")\n",
    "        save_img(after_filter, file, \"boxes_after_filters\")\n",
    "        save_img(result, file, \"filtered_result\")\n",
    "\n",
    "    return result\n",
    "\n",
    "def get_bitmap(gray, file=\"file.png\", DEBUG: bool = False):\n",
    "    \"\"\"\n",
    "    It takes in a square gray image and returns a bitmap of where text is present.\n",
    "\n",
    "    @param gray: a gray image\n",
    "    \n",
    "    @return: a bitmap of where text is present\n",
    "    \"\"\"\n",
    "\n",
    "    # get bitmap of where text is present\n",
    "    bitmap_raw = get_bitmap_of_possible_text(gray, sr=7, br=18, scale=12, file=file, DEBUG=DEBUG)\n",
    "\n",
    "    # filter bitmap\n",
    "    bitmap_text = filter_for_text(bitmap_raw, file=file, DEBUG=DEBUG)\n",
    "\n",
    "    return bitmap_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for image segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel(shape, lines, collumns) -> t.Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    It takes in a bitmap of where text is present and returns a square kernel to traverse the image.\n",
    "\n",
    "    @param shape: shape of an image to be split in <lines> and <collums>\n",
    "    @param lines: the number of lines to be split\n",
    "    @param collumns: the number of collums to be split\n",
    "\n",
    "    @return: a square kernel to traverse the image\n",
    "    \"\"\"\n",
    "    height, width = shape\n",
    "\n",
    "    lin_size = int(height / lines)\n",
    "    col_size = int(width / collumns)\n",
    "\n",
    "    kernel_size = min(lin_size, col_size)\n",
    "\n",
    "    return (kernel_size, kernel_size)\n",
    "\n",
    "def get_corners_of_segments(shape, kernel, overlap):\n",
    "    \"\"\"\n",
    "    It splits the image in smaller segments of size kernel that overlap by a percentage of overlap.\n",
    "    Note: the last on a line and collumn will overlap probably more\n",
    "\n",
    "    @param shape: the image's shape to be segmented\n",
    "    @param kernel: a square\n",
    "    @param overlap: the percentage of overlap (example: 30%)\n",
    "\n",
    "    @return: a list of corners where the segments will start \n",
    "    \"\"\"\n",
    "    kl = kernel[0] # kernel length\n",
    "    os = int(kl * overlap / 100) # overlap size\n",
    "    ns = kl - os # non-overlap size\n",
    "\n",
    "    height, width = shape\n",
    "\n",
    "    hsn = math.ceil((height - os) / ns) # number of segments on height\n",
    "    wsn = math.ceil((width  - os) / ns) # number of segments on width\n",
    "\n",
    "    corners = []\n",
    "\n",
    "    for i in range(0, hsn):\n",
    "        for j in range(0, wsn):\n",
    "            corner = [int(i * ns), int(j * ns)]\n",
    "            oposite_corner = (int(corner[0] + kl), int(corner[1] + kl))\n",
    "\n",
    "            # keep the segment in bounds even if for the last one we increase the overlay\n",
    "            if oposite_corner[0] > height:\n",
    "                corner[0] -= (oposite_corner[0] - height)\n",
    "            if oposite_corner[1] > width:\n",
    "                corner[1] -= (oposite_corner[1] - width)\n",
    "\n",
    "            corners.append((corner[0], corner[1]))\n",
    "\n",
    "    return corners\n",
    "\n",
    "def create_segments(img, kernel, corners, file=\"file.png\", DEBUG: bool = False):\n",
    "    \"\"\"\n",
    "    From the corner list, it splits the image in smaller segments of kernel size.\n",
    "\n",
    "    @param img: the image to be segmented\n",
    "    @param kernel: a square\n",
    "    @param corners: a list of corners where the segments will start\n",
    "\n",
    "    @return: a list of new images that represent the segments\n",
    "    \"\"\"\n",
    "    segments = []\n",
    "\n",
    "    for corner in corners:\n",
    "        s_img = img[corner[0]:corner[0]+kernel[0], corner[1]:corner[1]+kernel[1]]\n",
    "        segments.append((s_img, corner))\n",
    "\n",
    "    if DEBUG:\n",
    "        for i in range(0, len(segments)):\n",
    "            save_img(segments[i][0], file, \"segment_\" + str(i))\n",
    "\n",
    "    return segments\n",
    "\n",
    "def get_segments_k(img, kernel_size, overlap, file=\"file.png\", DEBUG: bool = False):\n",
    "    \"\"\"\n",
    "    It splits the image in smaller segments of size kernel that overlap by a\n",
    "    percentage of overlap.\n",
    "    Note: the last on a line and collumn will overlap probably more\n",
    "\n",
    "    @param img: the image to be segmented\n",
    "    @param kernel_size: the size of the kernel\n",
    "    @param overlap: the percentage of overlap (example: 30%)\n",
    "\n",
    "    @return: a list of new images that represent the segments\n",
    "    \"\"\"\n",
    "    kernel = (kernel_size, kernel_size)\n",
    "    segments = _get_segments(img, kernel, overlap, file, DEBUG)\n",
    "\n",
    "    return segments\n",
    "\n",
    "def get_segments_ck(img, lines, collumns, overlap, file=\"file.png\", DEBUG: bool = False):\n",
    "    \"\"\"\n",
    "    It calculates the kernel size and splits the image in smaller segments of size kernel\n",
    "    that overlap by a percentage of overlap.\n",
    "    Note: the last on a line and collumn will overlap probably more\n",
    "\n",
    "    @param img: the image to be segmented\n",
    "    @param lines: the number of lines to be split in\n",
    "    @param collumns: the number of collums to be split in\n",
    "    @param overlap: the percentage of overlap (example: 30%)\n",
    "\n",
    "    @return: a list of new images that represent the segments\n",
    "    \"\"\"\n",
    "    kernel = get_kernel(img.shape, lines, collumns)\n",
    "    segments = _get_segments(img, kernel, overlap, file, DEBUG)\n",
    "\n",
    "    return segments\n",
    "\n",
    "def _get_segments(img, kernel, overlap, file=\"file.png\", DEBUG: bool = False):\n",
    "\n",
    "    # print(file + \" -> \" + str(kernel), end=\"\\n\")\n",
    "    corners = get_corners_of_segments(img.shape, kernel, overlap=overlap)\n",
    "    segments = create_segments(img, kernel, corners, file=file, DEBUG=DEBUG)\n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voting process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vote(map, bitmap, corner):\n",
    "    \"\"\"\n",
    "    It finds boxes in the bitmap and votes for them in the map.\n",
    "\n",
    "    @param map: the map to vote in\n",
    "    @param bitmap: the bitmap to find boxes in\n",
    "    @param corner: the corner where the bitmap starts\n",
    "\n",
    "    @return: the updated vote map\n",
    "    \"\"\"\n",
    "    bitmap[bitmap > 0] = 1\n",
    "    map[corner[0]:corner[0]+bitmap.shape[0], corner[1]:corner[1]+bitmap.shape[1]] += bitmap\n",
    "    return map\n",
    "\n",
    "def filter_votes(voting_map, file=\"file.png\", DEBUG: bool = False):\n",
    "    # ensure all values in voting_map are uint8\n",
    "    voting_map = np.uint8(voting_map)\n",
    "\n",
    "    out_vm = voting_map.copy()\n",
    "\n",
    "    # threshold\n",
    "    vote_no: int = 3\n",
    "    voting_map[voting_map < vote_no] = 0\n",
    "\n",
    "    # make the map binary\n",
    "    voting_map[voting_map > 0] = 255\n",
    "\n",
    "    out_vm_after_threshold = voting_map.copy()\n",
    "\n",
    "    # find the contours in the vote map\n",
    "    cnts = cv2.findContours(voting_map.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    # for each contour, if it's too small, remove it\n",
    "    for c in cnts:\n",
    "        # get the bounding box of the contour\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "\n",
    "        # filter small boxes\n",
    "        if h < 40 or w < 10:\n",
    "            voting_map[y : y + h, x : x + w] = 0\n",
    "            \n",
    "    out_vm_after_filter_1 = voting_map.copy()\n",
    "    \n",
    "    # dilate the voting map\n",
    "    kernel_dilate = np.ones((1, 7), np.uint8)\n",
    "    voting_map = cv2.dilate(voting_map, kernel_dilate, iterations=5)\n",
    "\n",
    "    out_vm_after_dilate = voting_map.copy()\n",
    "\n",
    "    kernel_closing = np.ones((1, 37), np.uint8)    \n",
    "    voting_map = cv2.morphologyEx(voting_map, cv2.MORPH_CLOSE, kernel_closing)\n",
    "\n",
    "    out_vm_after_closing = voting_map.copy()\n",
    "\n",
    "    # add boxes to the image according to the voting map\n",
    "    # find the contours in the vote map\n",
    "    cnts = cv2.findContours(voting_map.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    # for each contour, if it's too small, remove it\n",
    "    for c in cnts:\n",
    "        # get the bounding box of the contour\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "\n",
    "        # draw only the bottom half\n",
    "        # if y < int(img.shape[0] * 0.5):\n",
    "        #     continue\n",
    "\n",
    "        # filter small boxes\n",
    "        if h < 40 or w < 10:\n",
    "            voting_map[y : y + h, x : x + w] = 0\n",
    "        # filter tall boxes\n",
    "        elif h > 200:\n",
    "            voting_map[y : y + h, x : x + w] = 0\n",
    "        # if a box is taller, check the ratio\n",
    "        elif h > 100 and h / w > 0.85:\n",
    "            voting_map[y : y + h, x : x + w] = 0\n",
    "\n",
    "    out_vm_after_filter_2 = voting_map.copy()\n",
    "\n",
    "    if DEBUG:\n",
    "        save_img(cv2.equalizeHist(out_vm), file, \"voting_map\")\n",
    "        save_img(out_vm_after_threshold, file, \"voting_map_after_threshold\")\n",
    "        save_img(out_vm_after_filter_1, file, \"voting_map_after_filter_1\")\n",
    "        save_img(out_vm_after_dilate, file, \"voting_map_after_dilate\")\n",
    "        save_img(out_vm_after_closing, file, \"voting_map_after_closing\")\n",
    "        save_img(out_vm_after_filter_2, file, \"voting_map_after_filter_2\")\n",
    "\n",
    "    return voting_map\n",
    "\n",
    "out_text_region = \"./detected/\"\n",
    "out_text_file_order = 0\n",
    "def save_detexted_text_region(img, contour, path=\"\"):\n",
    "    if path == \"\":\n",
    "        path = out_text_region\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    global out_text_file_order\n",
    "    # get the bounding box of the contour\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    # save the img box in another image\n",
    "    # format file name to 000n.png\n",
    "    file_name = str(out_text_file_order).zfill(2)\n",
    "    cv2.imwrite(path + file_name + \".png\", img[y : y + h, x : x + w])\n",
    "    out_text_file_order += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/mnt/HD/School/A4/licenta/notebook/code/playground/detect_text/evaluation/IMG_0022/IMG_0022-0-ROIs.png' -> './ROIs/IMG_0022.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/mnt/HD/School/A4/licenta/notebook/code/playground/detect_text/detect_text.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/HD/School/A4/licenta/notebook/code/playground/detect_text/detect_text.ipynb#ch0000012?line=49'>50</a>\u001b[0m     file_p \u001b[39m=\u001b[39m save_img(iwb, folder \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m file, \u001b[39m\"\u001b[39m\u001b[39mROIs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/HD/School/A4/licenta/notebook/code/playground/detect_text/detect_text.ipynb#ch0000012?line=50'>51</a>\u001b[0m     file_p \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(file_p)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/mnt/HD/School/A4/licenta/notebook/code/playground/detect_text/detect_text.ipynb#ch0000012?line=51'>52</a>\u001b[0m     os\u001b[39m.\u001b[39;49msymlink(file_p, \u001b[39m\"\u001b[39;49m\u001b[39m./ROIs/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m file)\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/HD/School/A4/licenta/notebook/code/playground/detect_text/detect_text.ipynb#ch0000012?line=53'>54</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAverage time: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39msum\u001b[39m(times) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(times)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/HD/School/A4/licenta/notebook/code/playground/detect_text/detect_text.ipynb#ch0000012?line=54'>55</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtimes: \u001b[39m\u001b[39m\"\u001b[39m, times)\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/mnt/HD/School/A4/licenta/notebook/code/playground/detect_text/evaluation/IMG_0022/IMG_0022-0-ROIs.png' -> './ROIs/IMG_0022.png'"
     ]
    }
   ],
   "source": [
    "reduced_proc = []\n",
    "times = []\n",
    "for folder in folders:\n",
    "    out_text_file_order = 0\n",
    "    ordn = 0\n",
    "\n",
    "    file = folder + \".png\"\n",
    "\n",
    "    if file != \"IMG_0022.png\":\n",
    "        continue\n",
    "    # break\n",
    "    img = cv2.imread(in_p + folder + \"/\" + file, cv2.IMREAD_COLOR)\n",
    "\n",
    "    t_start = time.time()\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    segments = get_segments_k(gray, kernel_size=400, overlap=75, file=file, DEBUG=False)\n",
    "\n",
    "    voting_map = np.zeros(gray.shape)\n",
    "\n",
    "    # for (s_img, corner) in segments[61:70]:\n",
    "    \n",
    "    for (s_img, corner) in segments[len(segments)//2:]:\n",
    "        # print(file + \" | corner -> \" + str(corner) + \" | out -> \" + str(ordn), end=\"\\n\")\n",
    "        bitmap = get_bitmap(s_img, file=file, DEBUG=False)\n",
    "        voting_map = vote(voting_map, bitmap, corner)\n",
    "\n",
    "    voting_map = filter_votes(voting_map, file=file, DEBUG=False)\n",
    "    t_finish = time.time()\n",
    "    times.append(t_finish - t_start)\n",
    "\n",
    "    # find connected components to save them in separate images\n",
    "    cnts = cv2.findContours(voting_map.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    # draw the bounding box\n",
    "    # print(\"\\t contours found:\", len(cnts))\n",
    "    iwb = img.copy()\n",
    "    total_size = 0\n",
    "    for c in cnts:\n",
    "        # get the bounding box of the contour\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        save_detexted_text_region(img, c, path=out_p + folder + \"/detected/\")\n",
    "        iwb = cv2.rectangle(iwb, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        total_size += w * h\n",
    "\n",
    "    reduced_proc.append(total_size / (img.shape[0] * img.shape[1]))\n",
    "\n",
    "    file_p = save_img(iwb, folder + \"/\" + file, \"ROIs\")\n",
    "    file_p = os.path.abspath(file_p)\n",
    "    os.symlink(file_p, \"./ROIs/\" + file)\n",
    "\n",
    "print(\"Average time: \" + str(sum(times) / len(times)))\n",
    "print(\"times: \", times)\n",
    "with open(out_p + \"times-stage2.txt\", \"w\") as f:\n",
    "    f.write(str(times))\n",
    "with open(out_p + \"reduced-stage2.txt\", \"w\") as f:\n",
    "    f.write(str(reduced_proc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
